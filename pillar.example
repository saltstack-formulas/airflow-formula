# -*- coding: utf-8 -*-
# vim: ft=yaml
---
# This file includes rabbitmq and postgres pillar data examples

airflow:
  identity:
    airflow:
      role: scheduler   # only for host running scheduler
      user: airflow
      group: airflow
      skip_user_state: true  # _airflow already exists
  database:
    airflow:
      user: airflow
      pass: airflow
      email: airflow@primaryhost
  config:
    airflow:
          {%- if grains.osfinger == 'CentOS Linux-7' %}
      venv_cmd: virtualenv-3
          {%- endif %}
      pip_cmd: pip3
      flask:
        # https://flask-appbuilder.readthedocs.io/en/latest/security.html#authentication-ldap
        auth_type: AUTH_LDAP
        auth_ldap_server: ldap://ldapserver.new    # must include protocol (ldap or ldaps)
        auth_ldap_append_domain: example.com
        auth_ldap_uid_field: 'sAMAccountName'  # or 'userPrincipalName'

        ## https://confluence.atlassian.com/kb/how-to-write-ldap-search-filters-792496933.html
        auth_ldap_search_filter: (&(objectCategory=Person)(sAMAccountName=*)(|memberOf=CN=myGrpRole,OU=myOrg,DC=example,DC=com)

        # auth_ldap_search: 'OU=ouEngineers_myteam,dc=example,dc=com'
        auth_user_registration_role: "Admin" # role, in addition to any AUTH_ROLES_MAPPING
        auth_user_registration: True   # allow users who are not already in the FAB DB
        webserver:
          web_server_host: 0.0.0.0
          web_server_port: 18080

      content:
        api: {}
        celery_kubernetes_executor: {}
        celery:
          # https://docs.celeryproject.org/en/v5.0.2/getting-started/brokers
          default_queue: /airflow
          broker_url: amqp://airflow:airflow@127.0.0.1:5672/airflow  # redis://127.0.0.1:6379/0
          result_backend: db+postgresql://airflow:airflow@primaryhost/airflow
        cli: {}
        core:
          dags_folder: /home/airflow/dags
          plugins_folder: /home/airflow/plugins
          executor: CeleryExecutor
          default_timezone: utc
          load_examples: True
          # https://stackoverflow.com/questions/45455342
          sql_alchemy_conn: postgresql+psycopg2://airflow:airflow@primaryhost/airflow
          security: ''
        webserver:
          secret_key: {{ range(1,2000) | random }}
      state_colors:
        # https://airflow.apache.org/docs/apache-airflow/stable/howto/customize-state-colors-ui.html
        queued: 'darkgray'
        running: '#01FF70'
        success: '#2ECC40'
        failed: 'firebrick'
        up_for_retry: 'yellow'
        up_for_reschedule: 'turquoise'
        upstream_failed: 'orange'
        skipped: 'darkorchid'
        scheduled: 'tan'
  service:
    airflow:
      enabled:
        - airflow-celery-flower
        - airflow-scheduler
        - airflow-webserver
        - airflow-celery-worker
  pkg:
    airflow:
      version: 2.1.0
          {%- if grains.osfinger == 'CentOS Linux-7' %}
          # because centos7 defaults to python2, need to be explicit
      uri_c: https://raw.githubusercontent.com/apache/airflow/constraints-VERSION/constraints-3.6.txt
          {%- endif %}
      extras:
        # https://airflow.apache.org/docs/apache-airflow/stable/installation.html#extra-packages
        # https://airflow.apache.org/docs/apache-airflow/stable/extra-packages-ref.html
        # Services Extras
        - async
        - crypto
        - dask
        - datadog           # Datadog hooks and sensors
        - devel
        - devel_ci
        - devel_azure
        - jira              # Jira hooks and operators
        - sendgrid          # Send email using sendgrid
        - slack             # airflow.providers.slack.operators.slack.SlackAPIOperator
        ## Software Extras
        - celery            # CeleryExecutor
        - cncf.kubernetes   # Kubernetes Executor and operator
        - docker            # Docker hooks and operators
        - ldap              # LDAP authentication for users
        - microsoft.azure
        - microsoft.mssql   # Microsoft SQL server
        - rabbitmq          # RabbitMQ support as a Celery backend
        - redis             # Redis hooks and sensors
        - statsd            # Needed by StatsD metrics
        - virtualenv
        ## Standard protocol Extras
        - cgroups           # Needed To use CgroupTaskRunner
        - grpc              # Grpc hooks and operators
        - http              # http hooks and providers
        - kerberos          # Kerberos integration
        - sftp
        - snowflake
        - sqlite
        - ssh               # SSH hooks and Operator
        - microsoft.winrm   # WinRM hooks and operators
  linux:
    altpriority: 0   # zero disables alternatives

postgres:
  version: 13
  postgresconf: |-
    listen_addresses = '*'  # or localhost,192.168.1.1'
  users:
    airflow:
      ensure: present
      password: airflow
      createdb: true
      inherit: true
      createroles: true
      replication: true
  databases:
    airflow:
      owner: airflow
  acls:
      # scope, db, user, [ cidr ] ..
    - ['local', 'airflow', 'airflow', 'md5']
    - ['local', 'all', 'all', 'peer']
    - ['host', 'all', 'all', '127.0.0.1/32', 'md5']
    - ['host', 'all', 'all', '191.168.1.1/32', 'md5']
    - ['host', 'all', 'all', '191.168.1.2/32', 'md5']
    - ['host', 'all', 'all', '::1/128', 'md5']
    - ['local', 'replication', 'all', 'peer']
    - ['host', 'replication', 'all', '127.0.0.1/32', 'md5']
    - ['host', 'replication', 'all', '::1/128', 'md5']

rabbitmq:
  cluster:
    rabbit@locahost:
      user: rabbit       # user is confusing keyname; should be 'node: rabbit'
      host: primaryhost  # host of node to join to
      ram_node: None
      runas: rabbitmq
      erlang_cookie:
        name: /var/lib/rabbitmq/.erlang.cookie
        value: shared-value-for-all-cluster-members
  vhost:
    - airflow
  user:
    airflow:
      - password: 'airflow'
      - force: true
      - tags:
        - management
        - administrator
      - perms:
          - 'airflow':
            - '.*'
            - '.*'
            - '.*'
      - runas: rabbitmq
  queue:
    airflow:
      - user: airflow
      - passwd: airflow
      - durable: true
      - auto_delete: false
      - vhost: airflow
      - arguments:
          - 'x-message-ttl': 8640000
          - 'x-expires': 8640000
          - 'x-dead-letter-exchange': 'airflow'
  binding:
    airflow:
      - destination_type: queue
      - destination: airflow
      - routing_key: airflow_routing_key
      - user: airflow
      - passwd: password
      - vhost: airflow
      - arguments:
          - 'x-message-ttl': 8640000
  exchange:
    airflow:
      - user: airflow
      - passwd: airflow
      - type: fanout
      - durable: true
      - internal: false
      - auto_delete: false
      - vhost: airflow
      - arguments:
          - 'alternate-**exchange': 'amq.fanout'
          - 'test-header': 'testing'
  policy: {}
  upstream: {}
...
